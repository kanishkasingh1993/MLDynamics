{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77d5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d82f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import DataLoader2D\n",
    "from plot_utils import animate_dyn,plot_eig,plot_perturbation,plot_wavepacket,comp_dyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d365e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp1 = nn.Conv2d(in_channels, mid_channels, 1)\n",
    "        self.mlp2 = nn.Conv2d(mid_channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.mlp2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "800d0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LpLoss(object):\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        #Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a470dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2,  width):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.padding = 9 # pad the domain if input is non-periodic\n",
    "\n",
    "        self.p = nn.Linear(4, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.mlp0 = MLP(self.width, self.width, self.width)\n",
    "        self.mlp1 = MLP(self.width, self.width, self.width)\n",
    "        self.mlp2 = MLP(self.width, self.width, self.width)\n",
    "        self.mlp3 = MLP(self.width, self.width, self.width)\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.q = MLP(self.width, 2, self.width * 4) # output channel is 1: u(x, y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #grid = self.get_grid(x.shape, x.device)\n",
    "        #x = torch.cat((x,V, grid), dim=-1)\n",
    "       # print(x.shape)\n",
    "        x = self.p(x)\n",
    "       # print(x.shape)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "       # x = F.pad(x, [0,self.padding, 0,self.padding])\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x1 = self.mlp0(x1)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.mlp1(x1)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x1 = self.mlp2(x1)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x1 = self.mlp3(x1)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "       # x = x[..., :-self.padding, :-self.padding]\n",
    "        x = self.q(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56719ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samp=1000\n",
    "ntrain=900\n",
    "ntest=100\n",
    "timestep=990\n",
    "batchsize=20\n",
    "epochs=100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb68b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'rb') as handle:\n",
    "    data_dict = pickle.load(handle)\n",
    "#data_dict = torch.load('data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7159cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "V=data_dict.get('V')\n",
    "u0=data_dict.get('u0')\n",
    "#D=data_dict.get('D')\n",
    "#U=data_dict.get('U')\n",
    "ux=data_dict.get('ux')\n",
    "U_real=data_dict.get('U_real')\n",
    "gridx=data_dict.get('gridx')\n",
    "gridt=data_dict.get('gridt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31dd6a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 300, 300]) torch.Size([1000, 300]) torch.Size([1000, 300]) torch.Size([1000, 300, 300, 2]) (300,) (300,)\n"
     ]
    }
   ],
   "source": [
    "print(V.shape,u0.shape,ux.shape,U_real.shape,gridx.shape,gridt.shape)\n",
    "#print(V.shape,u0.shape,D.shape,U.shape,ux.shape,U_real.shape,gridx.shape,gridt.shape)\n",
    "dataset=DataLoader2D(u0,U_real,V,timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653bb152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 300, 300]) torch.Size([900, 300, 300])\n",
      "torch.Size([900, 300, 300]) torch.Size([900, 300, 300]) torch.Size([900, 300, 300])\n",
      "torch.Size([900, 300, 300, 4]) torch.Size([900, 300, 300, 2]) torch.Size([900, 300, 300])\n",
      "torch.Size([100, 300, 300]) torch.Size([100, 300, 300])\n",
      "torch.Size([100, 300, 300]) torch.Size([100, 300, 300]) torch.Size([100, 300, 300])\n",
      "torch.Size([100, 300, 300, 4]) torch.Size([100, 300, 300, 2]) torch.Size([100, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "train_loader = dataset.make_loader(gridx,gridt,ntrain, batchsize, start=0, train=True)\n",
    "test_loader = dataset.make_loader(gridx,gridt,ntest, batchsize, start=ntrain, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8a3e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO2d(modes1=20,\n",
    "                  modes2=20,width=32)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e92e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_loader,epochs,device,batch_size):\n",
    "    \n",
    "    \n",
    "    \n",
    "    myloss = LpLoss(size_average=True)\n",
    "    learning_rate = 0.01\n",
    "    scheduler_step = 30\n",
    "    scheduler_gamma = 0.9\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler =  torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "    train_loss=[]\n",
    "\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        train_mse = 0\n",
    "        train_l2 = 0\n",
    "        model.train()        \n",
    "        for x,v,y in train_loader:\n",
    "            #print(x.shape)\n",
    "\n",
    "            x = x.to(device).float()\n",
    "            v=v.to(device)\n",
    "            y=y.to(device)\n",
    "            \n",
    "            #x.requires_grad=True\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = model(x).view(y.shape[0],300,300,2)\n",
    "            #data_loss = LpLoss(out, y)\n",
    "       \n",
    "            #out = model(x).view(batch_size, S, S, T)\n",
    "\n",
    "            mse = F.mse_loss(out, y, reduction='mean')\n",
    "        \n",
    "            l2 = myloss(out, y)\n",
    "            \n",
    "            l2.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "       \n",
    "            train_mse += mse.item()\n",
    "            train_l2 += l2.item()\n",
    "        \n",
    "        train_mse/= ntrain\n",
    "        train_l2 /= ntrain    \n",
    "        \n",
    "        \n",
    "        if (e%10==0):\n",
    "            print(e,train_l2,train_mse)\n",
    "        \n",
    "        train_loss.append(train_l2)    \n",
    "          \n",
    "   \n",
    "    return train_loss\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3769a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=train_model(model,train_loader,epochs,device,batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model.eval()\n",
    "test_l2 = 0.0\n",
    "test_mse=0.0\n",
    "V_out=[]\n",
    "pred_out=[]\n",
    "true_out=[]\n",
    "myloss = LpLoss(size_average=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,v, y in test_loader:\n",
    "            x = x.to(device).float()\n",
    "            \n",
    "            y=y.to(device)\n",
    "            \n",
    "            out = model(x).view(y.shape[0],300,300,2)\n",
    "            #data_loss = LpLoss(out, y)\n",
    "       \n",
    "            #out = model(x).view(batch_size, S, S, T)\n",
    "\n",
    "            mse = F.mse_loss(out, y, reduction='mean')\n",
    "        \n",
    "            l2 = myloss(out, y)\n",
    "            \n",
    "            #l2.backward()\n",
    "            \n",
    "            pred_out.append(out)\n",
    "            V_out.append(v)\n",
    "            true_out.append(y)\n",
    "            \n",
    "\n",
    "       \n",
    "            test_mse += mse.item()\n",
    "            test_l2 += l2.item()\n",
    "    \n",
    "    print(test_l2,test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8da815",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred_out),len(V_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pred_out[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pred_out[0][0].shape,V_out[0][0].shape,density_out[0].shape)\n",
    "#p1=pred_out[0][2]\n",
    "x=torch.view_as_complex(pred_out[1][1].contiguous())\n",
    "x_true=torch.view_as_complex(true_out[1][1].contiguous())\n",
    "dens=(x.abs()) ** 2\n",
    "dens_true=(x_true.abs()) ** 2\n",
    "#print(type(x),x.shape,dens.shape)\n",
    "v1=V_out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = -90*np.pi/180, 90*np.pi/180\n",
    "x_size, y_size = 300, 300\n",
    "x_grid = np.linspace(x_min, x_max, x_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "#%matplotlib notebook\n",
    "t=comp_dyn(x_min,x_max,0,100,x_grid,dens.cpu(),dens_true.cpu(),v1)\n",
    "#t.event_source.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fd4b5a3-925c-406a-96ae-add67aaf67ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.9262e-04, 1.7045e-04, 9.5592e-05, 1.6971e-04, 2.9066e-04, 3.9186e-04,\n",
      "        4.4398e-04, 4.5064e-04, 4.1558e-04, 3.9547e-04, 3.6431e-04, 3.3881e-04,\n",
      "        3.3323e-04, 3.2329e-04, 3.2746e-04, 3.2245e-04, 3.3011e-04, 3.2590e-04,\n",
      "        3.4214e-04, 3.5962e-04, 3.9443e-04, 4.2680e-04, 5.0329e-04, 6.1999e-04,\n",
      "        7.9587e-04, 1.0441e-03, 1.3796e-03, 1.7601e-03, 2.1084e-03, 2.3696e-03,\n",
      "        2.4555e-03, 2.3029e-03, 1.9174e-03, 1.4616e-03, 9.8224e-04, 5.8332e-04,\n",
      "        3.5149e-04, 2.6451e-04, 2.8929e-04, 3.7436e-04, 5.0656e-04, 6.8434e-04,\n",
      "        9.0760e-04, 1.2114e-03, 1.5449e-03, 1.8229e-03, 1.9682e-03, 1.9159e-03,\n",
      "        1.6844e-03, 1.3566e-03, 9.9369e-04, 6.9544e-04, 5.0036e-04, 3.8112e-04,\n",
      "        3.0310e-04, 2.1815e-04, 1.3367e-04, 5.4436e-05, 1.6126e-05, 1.4316e-05,\n",
      "        2.5201e-05, 6.0932e-05, 2.0214e-04, 6.5902e-04, 1.7866e-03, 4.1033e-03,\n",
      "        8.3917e-03, 1.5608e-02, 2.7214e-02, 4.5159e-02, 7.2209e-02, 1.1400e-01,\n",
      "        1.8141e-01, 3.0013e-01, 5.1494e-01, 8.9133e-01, 1.4796e+00, 2.2728e+00,\n",
      "        3.2215e+00, 4.2313e+00, 5.2158e+00, 6.0831e+00, 6.7869e+00, 7.3026e+00,\n",
      "        7.6055e+00, 7.6933e+00, 7.5519e+00, 7.1901e+00, 6.6197e+00, 5.8841e+00,\n",
      "        4.9959e+00, 4.0300e+00, 3.0570e+00, 2.1596e+00, 1.4112e+00, 8.4566e-01,\n",
      "        4.7445e-01, 2.6413e-01, 1.5585e-01, 1.0107e-01, 7.0662e-02, 5.1522e-02,\n",
      "        3.7829e-02, 2.7394e-02, 1.9324e-02, 1.3082e-02, 8.4359e-03, 5.0594e-03,\n",
      "        2.7176e-03, 1.2400e-03, 4.4568e-04, 8.7844e-05, 4.5021e-07, 8.0187e-05,\n",
      "        2.7149e-04, 5.3202e-04, 8.4325e-04, 1.1553e-03, 1.4204e-03, 1.6104e-03,\n",
      "        1.6828e-03, 1.6325e-03, 1.5057e-03, 1.3327e-03, 1.1372e-03, 9.6535e-04,\n",
      "        8.2168e-04, 7.2344e-04, 6.6526e-04, 5.9219e-04, 5.2896e-04, 4.4810e-04,\n",
      "        3.5326e-04, 2.5798e-04, 1.8703e-04, 1.6439e-04, 1.9625e-04, 2.6269e-04,\n",
      "        3.4938e-04, 4.2527e-04, 4.4279e-04, 4.1572e-04, 3.4612e-04, 2.6935e-04,\n",
      "        2.1957e-04, 2.2218e-04, 2.7168e-04, 3.5683e-04, 4.3999e-04, 5.1894e-04,\n",
      "        5.8737e-04, 6.1047e-04, 6.3091e-04, 6.4351e-04, 6.4527e-04, 6.3717e-04,\n",
      "        6.2099e-04, 5.7830e-04, 5.2485e-04, 4.4876e-04, 3.7758e-04, 3.1227e-04,\n",
      "        2.4267e-04, 1.9566e-04, 1.5843e-04, 1.3325e-04, 1.0752e-04, 9.5243e-05,\n",
      "        8.4362e-05, 7.5529e-05, 7.3483e-05, 7.6695e-05, 8.4919e-05, 1.0322e-04,\n",
      "        1.2994e-04, 1.6447e-04, 2.0833e-04, 2.6621e-04, 3.2570e-04, 3.9806e-04,\n",
      "        4.7982e-04, 5.7302e-04, 6.8678e-04, 8.1712e-04, 9.7358e-04, 1.1454e-03,\n",
      "        1.3069e-03, 1.4350e-03, 1.5071e-03, 1.4941e-03, 1.3927e-03, 1.1989e-03,\n",
      "        9.5391e-04, 6.9201e-04, 4.7329e-04, 3.1563e-04, 2.3668e-04, 2.3387e-04,\n",
      "        2.6674e-04, 3.0306e-04, 3.0416e-04, 2.6703e-04, 1.9693e-04, 1.2559e-04,\n",
      "        7.9354e-05, 8.8641e-05, 1.5793e-04, 2.8163e-04, 4.3314e-04, 5.9337e-04,\n",
      "        7.3292e-04, 8.3164e-04, 8.7103e-04, 8.7129e-04, 8.1679e-04, 7.2017e-04,\n",
      "        5.9947e-04, 4.6569e-04, 3.3608e-04, 2.2300e-04, 1.3547e-04, 7.7715e-05,\n",
      "        5.1854e-05, 4.5736e-05, 5.2894e-05, 5.9433e-05, 5.5636e-05, 3.9973e-05,\n",
      "        2.0787e-05, 7.1391e-06, 1.9564e-05, 6.8824e-05, 1.6035e-04, 2.7360e-04,\n",
      "        3.9953e-04, 5.0153e-04, 5.6624e-04, 5.6365e-04, 5.1773e-04, 4.4600e-04,\n",
      "        3.6976e-04, 3.1349e-04, 2.9570e-04, 3.0351e-04, 3.2921e-04, 3.5756e-04,\n",
      "        3.6563e-04, 3.5163e-04, 3.1380e-04, 2.6253e-04, 2.1302e-04, 1.6294e-04,\n",
      "        1.2390e-04, 9.3837e-05, 7.3204e-05, 6.2612e-05, 6.1218e-05, 7.2522e-05,\n",
      "        9.4277e-05, 1.2381e-04, 1.4655e-04, 1.5573e-04, 1.4877e-04, 1.1772e-04,\n",
      "        7.6881e-05, 3.6871e-05, 1.2428e-05, 3.5456e-06, 8.6462e-06, 1.7875e-05,\n",
      "        2.5986e-05, 2.9036e-05, 3.8768e-05, 6.0162e-05, 1.0234e-04, 1.6506e-04,\n",
      "        2.3033e-04, 2.7747e-04, 2.9359e-04, 2.7837e-04, 2.3388e-04, 1.7317e-04,\n",
      "        1.1374e-04, 6.9371e-05, 4.8757e-05, 4.6118e-05, 5.5008e-05, 6.5719e-05,\n",
      "        7.2993e-05, 7.3876e-05, 6.5135e-05, 5.6727e-05, 5.3858e-05, 5.8507e-05,\n",
      "        8.5369e-05, 1.6070e-04, 3.2362e-04, 6.3410e-04, 1.1619e-03, 1.9547e-03])\n"
     ]
    }
   ],
   "source": [
    "ax=dens.cpu()\n",
    "print(ax[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404bffc-8b31-481d-9222-30abfd9f12f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-1.1",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
